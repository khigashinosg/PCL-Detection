{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H08esTFOYO99"
      },
      "source": [
        "# Main imports and code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnHQoayhBYlm",
        "outputId": "cf7b52f1-6932-4e98-bc91-805cdf1d61f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Feb 28 17:00:26 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.146.02             Driver Version: 535.146.02   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A30                     Off | 00000000:02:00.0 Off |                   On |\n",
            "| N/A   31C    P0              26W / 165W |     50MiB / 24576MiB |     N/A      Default |\n",
            "|                                         |                      |              Enabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "\n",
            "+---------------------------------------------------------------------------------------+\n",
            "| MIG devices:                                                                          |\n",
            "+------------------+--------------------------------+-----------+-----------------------+\n",
            "| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n",
            "|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n",
            "|                  |                                |        ECC|                       |\n",
            "|==================+================================+===========+=======================|\n",
            "|  0    1   0   0  |              25MiB / 11968MiB  | 28      0 |  2   0    2    0    0 |\n",
            "|                  |               0MiB / 16383MiB  |           |                       |\n",
            "+------------------+--------------------------------+-----------+-----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check which gpu we're using\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYhFR7nSYOjG",
        "outputId": "2956495d-7e1d-4e86-fc05-fdb9e7065fc9"
      },
      "outputs": [],
      "source": [
        "# !pip install simpletransformers\n",
        "# !pip install tensorboardx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RJC8wj73Zd_p"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-28 18:01:00.341470: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-28 18:01:00.341596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-28 18:01:01.308568: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-28 18:01:03.793118: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-28 18:01:28.869090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs, MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
        "from urllib import request\n",
        "import pandas as pd\n",
        "import logging\n",
        "import torch\n",
        "from collections import Counter\n",
        "from ast import literal_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsX3b7ZNYVZe",
        "outputId": "6b4f657a-5998-41de-918f-43027865a588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda available?  True\n"
          ]
        }
      ],
      "source": [
        "# prepare logger\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# check gpu\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "print('Cuda available? ',cuda_available)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpRLLRzkTwdL",
        "outputId": "a478c5dc-1b3a-4bed-d33f-ba9a1460834c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-25 14:34:30.159101: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-25 14:34:30.163161: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-25 14:34:30.165587: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-25 14:34:30.316362: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-25 14:34:30.318229: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-25 14:34:30.319893: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-25 14:34:30.321513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 10275 MB memory:  -> device: 0, name: NVIDIA A30 MIG 2g.12gb, pci bus id: 0000:02:00.0, compute capability: 8.0\n"
          ]
        }
      ],
      "source": [
        "if cuda_available:\n",
        "  import tensorflow as tf\n",
        "  # Get the GPU device name.\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  # The device name should look like the following:\n",
        "  if device_name == '/device:GPU:0':\n",
        "      print('Found GPU at: {}'.format(device_name))\n",
        "  else:\n",
        "      raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMQDATlOZHxu"
      },
      "source": [
        "# Fetch Don't Patronize Me! data manager module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW903YxwThrH",
        "outputId": "a21ffb98-4e8e-4531-cad4-01aeaf0e9fa0"
      },
      "outputs": [],
      "source": [
        "# module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\"\n",
        "# module_name = module_url.split('/')[-1]\n",
        "# print(f'Fetching {module_url}')\n",
        "# #with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
        "# with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
        "#   a = f.read()\n",
        "#   outf.write(a.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRxm0179aqzw"
      },
      "outputs": [],
      "source": [
        "# helper function to save predictions to an output file\n",
        "def labels2file(p, outf_path):\n",
        "\twith open(outf_path,'w') as outf:\n",
        "\t\tfor pi in p:\n",
        "\t\t\toutf.write(','.join([str(k) for k in pi])+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcDThFWVBxGb"
      },
      "outputs": [],
      "source": [
        "from dont_patronize_me import DontPatronizeMe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ay5_5Y0ThrI"
      },
      "outputs": [],
      "source": [
        "dpm = DontPatronizeMe('.', '.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "2r3USK4eThrJ",
        "outputId": "fbee7cb0-c521-4c40-df2d-2bb2e2ebcdca"
      },
      "outputs": [],
      "source": [
        "dpm.load_task1()\n",
        "# dpm.load_task2(return_one_hot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0YcdU80IbiS"
      },
      "source": [
        "# Load paragraph IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AReWYHYOUqx"
      },
      "outputs": [],
      "source": [
        "trids = pd.read_csv('Data/train_semeval_parids-labels.csv')\n",
        "teids = pd.read_csv('Data/dev_semeval_parids-labels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IfCZjwQ16MS"
      },
      "outputs": [],
      "source": [
        "trids.par_id = trids.par_id.astype(str)\n",
        "teids.par_id = teids.par_id.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFnGtWdHJldw"
      },
      "outputs": [],
      "source": [
        "data=dpm.train_task1_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmUBJhljbnpN"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>par_id</th>\n",
              "      <th>art_id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>orig_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@@24942188</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>ph</td>\n",
              "      <td>We 're living in times of absolute insanity , ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@@21968160</td>\n",
              "      <td>migrant</td>\n",
              "      <td>gh</td>\n",
              "      <td>In Libya today , there are countless number of...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>@@16584954</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>ie</td>\n",
              "      <td>\"White House press secretary Sean Spicer said ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>@@7811231</td>\n",
              "      <td>disabled</td>\n",
              "      <td>nz</td>\n",
              "      <td>Council customers only signs would be displaye...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>@@1494111</td>\n",
              "      <td>refugee</td>\n",
              "      <td>ca</td>\n",
              "      <td>\"\"\" Just like we received migrants fleeing El ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10464</th>\n",
              "      <td>10465</td>\n",
              "      <td>@@14297363</td>\n",
              "      <td>women</td>\n",
              "      <td>lk</td>\n",
              "      <td>\"Sri Lankan norms and culture inhibit women fr...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10465</th>\n",
              "      <td>10466</td>\n",
              "      <td>@@70091353</td>\n",
              "      <td>vulnerable</td>\n",
              "      <td>ph</td>\n",
              "      <td>He added that the AFP will continue to bank on...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10466</th>\n",
              "      <td>10467</td>\n",
              "      <td>@@20282330</td>\n",
              "      <td>in-need</td>\n",
              "      <td>ng</td>\n",
              "      <td>\"\"\" She has one huge platform , and informatio...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10467</th>\n",
              "      <td>10468</td>\n",
              "      <td>@@16753236</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>in</td>\n",
              "      <td>\"\"\" Anja Ringgren Loven I ca n't find a word t...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10468</th>\n",
              "      <td>10469</td>\n",
              "      <td>@@16779383</td>\n",
              "      <td>homeless</td>\n",
              "      <td>ie</td>\n",
              "      <td>\"\"\" Guinness World Record of 540lbs of 7-layer...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10469 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      par_id      art_id     keyword country  \\\n",
              "0          1  @@24942188    hopeless      ph   \n",
              "1          2  @@21968160     migrant      gh   \n",
              "2          3  @@16584954   immigrant      ie   \n",
              "3          4   @@7811231    disabled      nz   \n",
              "4          5   @@1494111     refugee      ca   \n",
              "...      ...         ...         ...     ...   \n",
              "10464  10465  @@14297363       women      lk   \n",
              "10465  10466  @@70091353  vulnerable      ph   \n",
              "10466  10467  @@20282330     in-need      ng   \n",
              "10467  10468  @@16753236    hopeless      in   \n",
              "10468  10469  @@16779383    homeless      ie   \n",
              "\n",
              "                                                    text  label orig_label  \n",
              "0      We 're living in times of absolute insanity , ...      0          0  \n",
              "1      In Libya today , there are countless number of...      0          0  \n",
              "2      \"White House press secretary Sean Spicer said ...      0          0  \n",
              "3      Council customers only signs would be displaye...      0          0  \n",
              "4      \"\"\" Just like we received migrants fleeing El ...      0          0  \n",
              "...                                                  ...    ...        ...  \n",
              "10464  \"Sri Lankan norms and culture inhibit women fr...      0          1  \n",
              "10465  He added that the AFP will continue to bank on...      0          0  \n",
              "10466  \"\"\" She has one huge platform , and informatio...      1          3  \n",
              "10467  \"\"\" Anja Ringgren Loven I ca n't find a word t...      1          4  \n",
              "10468  \"\"\" Guinness World Record of 540lbs of 7-layer...      1          3  \n",
              "\n",
              "[10469 rows x 7 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lXrNj_Ww_FC"
      },
      "source": [
        "\n",
        "\n",
        "# Rebuild training set (Task 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOxDR1H2g_3p"
      },
      "outputs": [],
      "source": [
        "rows = [] # will contain par_id, label and text\n",
        "for idx in range(len(trids)):\n",
        "  parid = trids.par_id[idx]\n",
        "  #print(parid)\n",
        "  # select row from original dataset to retrieve `text` and binary label\n",
        "  keyword = data.loc[data.par_id == parid].keyword.values[0]\n",
        "  text = data.loc[data.par_id == parid].text.values[0]\n",
        "  label = data.loc[data.par_id == parid].label.values[0]\n",
        "  rows.append({\n",
        "      'par_id':parid,\n",
        "      'community':keyword,\n",
        "      'text':text,\n",
        "      'label':label\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7UDCLIgcrCl"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e3E08Yown5p"
      },
      "outputs": [],
      "source": [
        "trdf1 = pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgxtVuhr9ZFG"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>par_id</th>\n",
              "      <th>community</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4341</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>The scheme saw an estimated 150,000 children f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4136</td>\n",
              "      <td>homeless</td>\n",
              "      <td>Durban 's homeless communities reconciliation ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10352</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>The next immediate problem that cropped up was...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8279</td>\n",
              "      <td>vulnerable</td>\n",
              "      <td>Far more important than the implications for t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1164</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>To strengthen child-sensitive social protectio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8370</th>\n",
              "      <td>8380</td>\n",
              "      <td>refugee</td>\n",
              "      <td>Rescue teams search for survivors on the rubbl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8371</th>\n",
              "      <td>8381</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>The launch of ' Happy Birthday ' took place la...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8372</th>\n",
              "      <td>8382</td>\n",
              "      <td>homeless</td>\n",
              "      <td>The unrest has left at least 20,000 people dea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8373</th>\n",
              "      <td>8383</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>You have to see it from my perspective . I may...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8374</th>\n",
              "      <td>8384</td>\n",
              "      <td>disabled</td>\n",
              "      <td>Yet there was one occasion when we went to the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8375 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     par_id      community                                               text  \\\n",
              "0      4341  poor-families  The scheme saw an estimated 150,000 children f...   \n",
              "1      4136       homeless  Durban 's homeless communities reconciliation ...   \n",
              "2     10352  poor-families  The next immediate problem that cropped up was...   \n",
              "3      8279     vulnerable  Far more important than the implications for t...   \n",
              "4      1164  poor-families  To strengthen child-sensitive social protectio...   \n",
              "...     ...            ...                                                ...   \n",
              "8370   8380        refugee  Rescue teams search for survivors on the rubbl...   \n",
              "8371   8381       hopeless  The launch of ' Happy Birthday ' took place la...   \n",
              "8372   8382       homeless  The unrest has left at least 20,000 people dea...   \n",
              "8373   8383       hopeless  You have to see it from my perspective . I may...   \n",
              "8374   8384       disabled  Yet there was one occasion when we went to the...   \n",
              "\n",
              "      label  \n",
              "0         1  \n",
              "1         1  \n",
              "2         1  \n",
              "3         1  \n",
              "4         1  \n",
              "...     ...  \n",
              "8370      0  \n",
              "8371      0  \n",
              "8372      0  \n",
              "8373      0  \n",
              "8374      0  \n",
              "\n",
              "[8375 rows x 4 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trdf1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1KGYmpnxDjt"
      },
      "source": [
        "# Rebuild test set (Task 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6FLgB6KxGI2"
      },
      "outputs": [],
      "source": [
        "rows = [] # will contain par_id, label and text\n",
        "for idx in range(len(teids)):\n",
        "  parid = teids.par_id[idx]\n",
        "  #print(parid)\n",
        "  # select row from original dataset\n",
        "  keyword = data.loc[data.par_id == parid].keyword.values[0]\n",
        "  text = data.loc[data.par_id == parid].text.values[0]\n",
        "  label = data.loc[data.par_id == parid].label.values[0]\n",
        "  rows.append({\n",
        "      'par_id':parid,\n",
        "      'community':keyword,\n",
        "      'text':text,\n",
        "      'label':label\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbB9GdzJxRAH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2094"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhBhTRIyxSaQ"
      },
      "outputs": [],
      "source": [
        "tedf1 = pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuaH7i69aud6"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "1154",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1154",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtedf1\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/random.py:394\u001b[0m, in \u001b[0;36mRandom.shuffle\u001b[0;34m(self, x, random)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(x))):\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# pick an element in x[:i+1] with which to exchange x[i]\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         j \u001b[38;5;241m=\u001b[39m randbelow(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 394\u001b[0m         x[i], x[j] \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m, x[i]\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     _warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe *random* parameter to shuffle() has been deprecated\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    397\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msince Python 3.9 and will be removed in a subsequent \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    398\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    399\u001b[0m           \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, \u001b[38;5;241m2\u001b[39m)\n",
            "File \u001b[0;32m/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 1154"
          ]
        }
      ],
      "source": [
        "random.shuffle(tedf1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK6FY70KZ6TY"
      },
      "source": [
        "# RoBERTa Baseline for Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-pvjbu_8h1n"
      },
      "outputs": [],
      "source": [
        "# downsample negative instances\n",
        "pcldf = trdf1[trdf1.label==1]\n",
        "npos = len(pcldf)\n",
        "\n",
        "training_set1 = pd.concat([pcldf,trdf1[trdf1.label==0][:npos*2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpSqMp3d8iYu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>par_id</th>\n",
              "      <th>community</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4341</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>The scheme saw an estimated 150,000 children f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4136</td>\n",
              "      <td>homeless</td>\n",
              "      <td>Durban 's homeless communities reconciliation ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10352</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>The next immediate problem that cropped up was...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8279</td>\n",
              "      <td>vulnerable</td>\n",
              "      <td>Far more important than the implications for t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1164</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>To strengthen child-sensitive social protectio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2377</th>\n",
              "      <td>1775</td>\n",
              "      <td>refugee</td>\n",
              "      <td>Last but not the least element of culpability ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2378</th>\n",
              "      <td>1776</td>\n",
              "      <td>refugee</td>\n",
              "      <td>Then , taking the art of counter-intuitive non...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>1777</td>\n",
              "      <td>refugee</td>\n",
              "      <td>Kagunga village was reported to lack necessary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2380</th>\n",
              "      <td>1778</td>\n",
              "      <td>vulnerable</td>\n",
              "      <td>\"After her parents high-profile divorce after ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2381</th>\n",
              "      <td>1779</td>\n",
              "      <td>in-need</td>\n",
              "      <td>\"Last night One News reported on leaked Minist...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2382 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     par_id      community                                               text  \\\n",
              "0      4341  poor-families  The scheme saw an estimated 150,000 children f...   \n",
              "1      4136       homeless  Durban 's homeless communities reconciliation ...   \n",
              "2     10352  poor-families  The next immediate problem that cropped up was...   \n",
              "3      8279     vulnerable  Far more important than the implications for t...   \n",
              "4      1164  poor-families  To strengthen child-sensitive social protectio...   \n",
              "...     ...            ...                                                ...   \n",
              "2377   1775        refugee  Last but not the least element of culpability ...   \n",
              "2378   1776        refugee  Then , taking the art of counter-intuitive non...   \n",
              "2379   1777        refugee  Kagunga village was reported to lack necessary...   \n",
              "2380   1778     vulnerable  \"After her parents high-profile divorce after ...   \n",
              "2381   1779        in-need  \"Last night One News reported on leaked Minist...   \n",
              "\n",
              "      label  \n",
              "0         1  \n",
              "1         1  \n",
              "2         1  \n",
              "3         1  \n",
              "4         1  \n",
              "...     ...  \n",
              "2377      0  \n",
              "2378      0  \n",
              "2379      0  \n",
              "2380      0  \n",
              "2381      0  \n",
              "\n",
              "[2382 rows x 4 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoW_s23AZ_DG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:610: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
            "  warnings.warn(\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "763e17f7a228438a81a9218a4c8a34fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m task1_model \u001b[38;5;241m=\u001b[39m ClassificationModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                   args \u001b[38;5;241m=\u001b[39m task1_model_args,\n\u001b[1;32m      8\u001b[0m                                   num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                   use_cuda\u001b[38;5;241m=\u001b[39mcuda_available)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtask1_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_set1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# run predictions\u001b[39;00m\n\u001b[1;32m     13\u001b[0m preds_task1, _ \u001b[38;5;241m=\u001b[39m task1_model\u001b[38;5;241m.\u001b[39mpredict(tedf1\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mtolist())\n",
            "File \u001b[0;32m/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:617\u001b[0m, in \u001b[0;36mClassificationModel.train_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    611\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    612\u001b[0m         )\n\u001b[1;32m    613\u001b[0m         train_examples \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    614\u001b[0m             train_df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    615\u001b[0m             train_df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    616\u001b[0m         )\n\u001b[0;32m--> 617\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_cache_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m train_sampler \u001b[38;5;241m=\u001b[39m RandomSampler(train_dataset)\n\u001b[1;32m    621\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m    622\u001b[0m     train_dataset,\n\u001b[1;32m    623\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mtrain_sampler,\n\u001b[1;32m    624\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_batch_size,\n\u001b[1;32m    625\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_num_workers,\n\u001b[1;32m    626\u001b[0m )\n",
            "File \u001b[0;32m/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:1824\u001b[0m, in \u001b[0;36mClassificationModel.load_and_cache_examples\u001b[0;34m(self, examples, evaluate, no_cache, multi_label, verbose, silent)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1824\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mClassificationDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1826\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1827\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1830\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1833\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
            "File \u001b[0;32m/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/simpletransformers/classification/classification_utils.py:282\u001b[0m, in \u001b[0;36mClassificationDataset.__init__\u001b[0;34m(self, data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, tokenizer, args, mode, multi_label, output_mode, no_cache):\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexamples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_classification_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_cache\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/simpletransformers/classification/classification_utils.py:249\u001b[0m, in \u001b[0;36mbuild_classification_dataset\u001b[0;34m(data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    243\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    244\u001b[0m             (text_a[i : i \u001b[38;5;241m+\u001b[39m chunksize], \u001b[38;5;28;01mNone\u001b[39;00m, tokenizer, args\u001b[38;5;241m.\u001b[39mmax_seq_length)\n\u001b[1;32m    245\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(text_a), chunksize)\n\u001b[1;32m    246\u001b[0m         ]\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(args\u001b[38;5;241m.\u001b[39mprocess_count) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m--> 249\u001b[0m         examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_data_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_a\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     examples \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    258\u001b[0m         key: torch\u001b[38;5;241m.\u001b[39mcat([example[key] \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m examples])\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m examples[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    260\u001b[0m     }\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
            "File \u001b[0;32m/vol/bitbucket/kh123/llm/venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
            "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "task1_model_args = ClassificationArgs(num_train_epochs=1,\n",
        "                                      no_save=True,\n",
        "                                      no_cache=True,\n",
        "                                      overwrite_output_dir=True)\n",
        "task1_model = ClassificationModel(\"roberta\",\n",
        "                                  'roberta-base',\n",
        "                                  args = task1_model_args,\n",
        "                                  num_labels=2,\n",
        "                                  use_cuda=cuda_available)\n",
        "# train model\n",
        "task1_model.train_model(training_set1[['text', 'label']])\n",
        "# run predictions\n",
        "preds_task1, _ = task1_model.predict(tedf1.text.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5oxHt2R6t2I"
      },
      "outputs": [],
      "source": [
        "Counter(preds_task1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzupJuwTafKa"
      },
      "outputs": [],
      "source": [
        "labels2file([[k] for k in preds_task1], 'task1.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Cc_u5Oli7j"
      },
      "source": [
        "# Rebuild training set (Task 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2WLYT7wli7k"
      },
      "outputs": [],
      "source": [
        "rows2 = [] # will contain par_id, label and text\n",
        "for idx in range(len(trids)):\n",
        "  parid = trids.par_id[idx]\n",
        "  label = trids.label[idx]\n",
        "  # select row from original dataset to retrieve the `text` value\n",
        "  text = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].text.values[0]\n",
        "  rows2.append({\n",
        "      'par_id':parid,\n",
        "      'text':text,\n",
        "      'label':label\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFqMMb5Jli7l"
      },
      "outputs": [],
      "source": [
        "trdf2 = pd.DataFrame(rows2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HayrC9q7mQPl"
      },
      "outputs": [],
      "source": [
        "trdf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxHLB_g0pfEb"
      },
      "outputs": [],
      "source": [
        "trdf2.label = trdf2.label.apply(literal_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gukbmv0bli7l"
      },
      "source": [
        "# Rebuild test set (Task 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjH-AJK1li7m"
      },
      "outputs": [],
      "source": [
        "rows2 = [] # will contain par_id, label and text\n",
        "for idx in range(len(teids)):\n",
        "  parid = teids.par_id[idx]\n",
        "  label = teids.label[idx]\n",
        "  #print(parid)\n",
        "  # select row from original dataset to access the `text` value\n",
        "  text = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].text.values[0]\n",
        "  rows2.append({\n",
        "      'par_id':parid,\n",
        "      'text':text,\n",
        "      'label':label\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRP-tn5wli7n"
      },
      "outputs": [],
      "source": [
        "tedf2 = pd.DataFrame(rows2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U2lrfJiolku"
      },
      "outputs": [],
      "source": [
        "tedf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81aQFjWqpbe2"
      },
      "outputs": [],
      "source": [
        "tedf2.label = tedf2.label.apply(literal_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKFiVaslbAiC"
      },
      "source": [
        "# RoBERTa baseline for Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmr5ZZf5Ik5T"
      },
      "outputs": [],
      "source": [
        "all_negs = trdf2[trdf2.label.apply(lambda x:sum(x) == 0)]\n",
        "all_pos = trdf2[trdf2.label.apply(lambda x:sum(x) > 0)]\n",
        "\n",
        "training_set2 = pd.concat([all_pos,all_negs[:round(len(all_pos)*0.5)]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyBcJoHtJHE2"
      },
      "outputs": [],
      "source": [
        "training_set2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECb7_mwzbFa6"
      },
      "outputs": [],
      "source": [
        "task2_model_args = MultiLabelClassificationArgs(num_train_epochs=1,\n",
        "                                                no_save=True,\n",
        "                                                no_cache=True,\n",
        "                                                overwrite_output_dir=True\n",
        "                                                )\n",
        "task2_model = MultiLabelClassificationModel(\"roberta\",\n",
        "                                            'roberta-base',\n",
        "                                            num_labels=7,\n",
        "                                            args = task2_model_args,\n",
        "                                            use_cuda=cuda_available)\n",
        "# train model\n",
        "task2_model.train_model(training_set2[['text', 'label']])\n",
        "# run predictions\n",
        "preds_task2, _ = task2_model.predict(tedf2.text.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0211sxhsbbWZ"
      },
      "outputs": [],
      "source": [
        "labels2file(preds_task2, 'task2.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT8hjnxbbfJq"
      },
      "source": [
        "## Prepare submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7HICl8MJQf0"
      },
      "outputs": [],
      "source": [
        "!cat task1.txt | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCjziGtxJRif"
      },
      "outputs": [],
      "source": [
        "!cat task2.txt | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZDLUcYZbhYg"
      },
      "outputs": [],
      "source": [
        "!zip submission.zip task1.txt task2.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
