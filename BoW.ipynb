{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from dont_patronize_me import DontPatronizeMe\n",
    "\n",
    "### load in raw data\n",
    "dpm = DontPatronizeMe('./Data', '.')\n",
    "dpm.load_task1()\n",
    "# dpm.load_task2(return_one_hot=True)\n",
    "data=dpm.train_task1_df\n",
    "\n",
    "trids = pd.read_csv('Data/train_semeval_parids-labels.csv')\n",
    "teids = pd.read_csv('Data/dev_semeval_parids-labels.csv')\n",
    "trids.par_id = trids.par_id.astype(str)\n",
    "teids.par_id = teids.par_id.astype(str)\n",
    "\n",
    "# make train dataset\n",
    "rows = [] \n",
    "for idx in range(len(trids)):  \n",
    "  parid = trids.par_id[idx]\n",
    "  keyword = data.loc[data.par_id == parid].keyword.values[0]\n",
    "  text = data.loc[data.par_id == parid].text.values[0]\n",
    "  label = data.loc[data.par_id == parid].label.values[0]\n",
    "  rows.append({\n",
    "      'par_id':parid,\n",
    "      'community':keyword,\n",
    "      'text':text,\n",
    "      'label':label\n",
    "  })\n",
    "trdf1 = pd.DataFrame(rows)\n",
    "\n",
    "# make dev dataset\n",
    "rows = []\n",
    "for idx in range(len(teids)):  \n",
    "  parid = teids.par_id[idx]\n",
    "  keyword = data.loc[data.par_id == parid].keyword.values[0]\n",
    "  text = data.loc[data.par_id == parid].text.values[0]\n",
    "  label = data.loc[data.par_id == parid].label.values[0]\n",
    "  rows.append({\n",
    "      'par_id':parid,\n",
    "      'community':keyword,\n",
    "      'text':text,\n",
    "      'label':label\n",
    "  })\n",
    "tedf1 = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run BoW on raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9054441260744985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1895\n",
      "           1       0.54      0.04      0.07       199\n",
      "\n",
      "    accuracy                           0.91      2094\n",
      "   macro avg       0.72      0.52      0.51      2094\n",
      "weighted avg       0.87      0.91      0.87      2094\n",
      "\n",
      "par_id                                                     8542\n",
      "community                                              homeless\n",
      "text          A homeless couple is seen by the roadside alon...\n",
      "label                                                         0\n",
      "prediction                                                    1\n",
      "Name: 345, dtype: object\n",
      "A homeless couple is seen by the roadside along Jalan Tuanku Abdul Rahman . -- Picture by Choo Choy May\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare dataset\n",
    "train_df = trdf1.copy()\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "dev_df = tedf1\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train = train_df[\"text\"]\n",
    "y_train = train_df['label']\n",
    "X_test = dev_df[\"text\"]\n",
    "y_test = dev_df[\"label\"]\n",
    "\n",
    "# Step 3: Extract features using BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 4: Train the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "# Step 5: Evaluate the classifier\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Append predictions to validation dataset\n",
    "tedf1[\"prediction\"] = y_pred\n",
    "\n",
    "# extract example where prediction was PCL but it was actually no-PCL\n",
    "new_df = tedf1[(tedf1[\"label\"] == 0) & (tedf1[\"prediction\"] == 1)]\n",
    "print(new_df.iloc[0])\n",
    "print(new_df[\"text\"].iloc[0])\n",
    "\n",
    "mispredict_example = new_df[\"text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'homeless', 'couple', 'is', 'seen', 'by', 'the', 'roadside', 'along', 'Jalan', 'Tuanku', 'Abdul', 'Rahman', '.', '--', 'Picture', 'by', 'Choo', 'Choy', 'May']\n",
      "        Feature  Class 0 Log Prob  Class 1 Log Prob\n",
      "1546      along            -8.358            -9.270\n",
      "3986         by            -5.354            -5.926\n",
      "5878     couple            -9.141            -9.963\n",
      "11332  homeless            -6.232            -6.058\n",
      "12578        is            -4.678            -5.021\n",
      "20719  roadside           -11.366           -11.062\n",
      "21582      seen            -8.462            -8.664\n",
      "24164       the            -2.915            -3.393\n",
      "class 0 prob -56.506\n",
      "class 1 prob -59.357\n"
     ]
    }
   ],
   "source": [
    "# extract log probabilities \n",
    "log_probabilities = clf.feature_log_prob_\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "class_0_probabilities = log_probabilities[0]\n",
    "class_1_probabilities = log_probabilities[1]\n",
    "\n",
    "# build a dataframe containing all words and their probabilities\n",
    "probabilities_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Class 0 Log Prob': class_0_probabilities,\n",
    "    'Class 1 Log Prob': class_1_probabilities\n",
    "}).round(3)\n",
    "\n",
    "# \"tokenise\" mispredicted example\n",
    "mispredict_example_list = mispredict_example.split(\" \")\n",
    "print(mispredict_example_list)\n",
    "\n",
    "# extract the log probabilities of all the words mispredicted example\n",
    "probs_of_example_df = probabilities_df[probabilities_df[\"Feature\"].isin(mispredict_example_list)]\n",
    "print(probs_of_example_df)\n",
    "\n",
    "# calculate the total log probability of the sentence (for both class 0 and 1)\n",
    "class_0_prob = probs_of_example_df[\"Class 0 Log Prob\"].sum()\n",
    "class_1_prob = probs_of_example_df[\"Class 1 Log Prob\"].sum()\n",
    "\n",
    "# print\n",
    "print(\"class 0 prob\",class_0_prob)\n",
    "print(\"class 1 prob\", class_1_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampled train-train vs train val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio 9.54911838790932\n",
      "Training data is balanced\n",
      "Training data length 15164\n",
      "Accuracy: 0.8375537505972288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91      1894\n",
      "           1       0.31      0.57      0.40       199\n",
      "\n",
      "    accuracy                           0.84      2093\n",
      "   macro avg       0.63      0.72      0.65      2093\n",
      "weighted avg       0.89      0.84      0.86      2093\n",
      "\n",
      "     par_id      art_id        keyword country  \\\n",
      "0      9946   @@9395009     vulnerable      ke   \n",
      "1      2421  @@15077401       disabled      za   \n",
      "2     10138   @@3695746      immigrant      gb   \n",
      "3      6976  @@25505334        refugee      lk   \n",
      "4      9410   @@2424134     vulnerable      ie   \n",
      "...     ...         ...            ...     ...   \n",
      "2088   5482   @@4538978       disabled      pk   \n",
      "2089   1119  @@16163174     vulnerable      pk   \n",
      "2090   7540  @@24149675  poor-families      ke   \n",
      "2091   4137   @@4553170          women      jm   \n",
      "2092   3830  @@21639901       homeless      in   \n",
      "\n",
      "                                                   text  label orig_label  \\\n",
      "0     \"\"\" Today 's decision upholds and affirms Amer...      1          3   \n",
      "1     Mandla Moyo showed pictures of his late disabl...      0          0   \n",
      "2     Sweden has reacted with shock and horror after...      0          0   \n",
      "3     In August 2015 the Sri Lankan man sued the gov...      0          0   \n",
      "4     She was only 26 at the time and looks like a t...      1          3   \n",
      "...                                                 ...    ...        ...   \n",
      "2088  The three girls were found dead in a trough , ...      0          0   \n",
      "2089  LONDON : Billionaire philanthropist Bill Gates...      0          0   \n",
      "2090  At the same time , Makueni County government h...      0          0   \n",
      "2091  Thirty years ago , the great US sex researcher...      0          0   \n",
      "2092  The Banyan would execute this programme in all...      0          0   \n",
      "\n",
      "      prediction  \n",
      "0              1  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "...          ...  \n",
      "2088           0  \n",
      "2089           0  \n",
      "2090           0  \n",
      "2091           0  \n",
      "2092           0  \n",
      "\n",
      "[2093 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_546254/1655084262.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_df[\"prediction\"] = y_pred\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows for the 20% testing split\n",
    "test_size = int(len(data) * 0.2)\n",
    "\n",
    "# Step 1: Shuffle and split raw data\n",
    "shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "val_df = shuffled_data.iloc[:test_size]  # First 20%\n",
    "train_df = shuffled_data.iloc[test_size:]  # Last 80%\n",
    "\n",
    "# Separate positive and negative samples in TRAIN data only (don't touch TEST data)\n",
    "positive_samples = train_df[train_df['label'] == 1]\n",
    "negative_samples = train_df[train_df['label'] == 0]\n",
    "\n",
    "# Calculate resampling ratio\n",
    "ratio = len(negative_samples) / len(positive_samples)\n",
    "print(\"ratio\", ratio)\n",
    "\n",
    "# Upsample positive samples\n",
    "upsampled_positive = positive_samples.sample(frac=ratio, replace=True, random_state=42)\n",
    "\n",
    "# Concatenate upsampled positive samples with original negative samples\n",
    "upsampled_df = pd.concat([negative_samples, upsampled_positive])\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "upsampled_df = upsampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check dataset is balanced\n",
    "num_positive = len(upsampled_df[upsampled_df['label'] == 1])\n",
    "num_negative = len(upsampled_df[upsampled_df['label'] == 0])\n",
    "assert num_positive == num_negative, \"Training data is not balanced\"\n",
    "print(\"Training data is balanced\")\n",
    "print(\"Training data length\",len(upsampled_df))\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train = upsampled_df[\"text\"]\n",
    "y_train = upsampled_df['label']\n",
    "X_val = val_df[\"text\"]\n",
    "y_val = val_df[\"label\"]\n",
    "\n",
    "# Step 3: Extract features using BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_val_counts = vectorizer.transform(X_val) # only transform, dont fit\n",
    "\n",
    "# Step 4: Train the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "# Step 5: Evaluate the classifier\n",
    "y_pred = clf.predict(X_val_counts)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Append predictions to validation dataset\n",
    "val_df[\"prediction\"] = y_pred\n",
    "print(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampled Train vs Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio 9.547858942065492\n",
      "Training data is balanced\n",
      "Training data length 15162\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2093, 2094]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Step 5: Evaluate the classifier\u001b[39;00m\n\u001b[1;32m     46\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test_counts)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_val, y_pred))\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Append predictions to validation dataset\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/kh123/nlp_cw/venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/vol/bitbucket/kh123/nlp_cw/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/vol/bitbucket/kh123/nlp_cw/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/kh123/nlp_cw/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2093, 2094]"
     ]
    }
   ],
   "source": [
    "# Step 1: Shuffle and split raw data\n",
    "train_df = trdf1.copy()\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "dev_df = tedf1\n",
    "\n",
    "# Separate positive and negative samples in TRAIN data only (don't touch TEST data)\n",
    "positive_samples = train_df[train_df['label'] == 1]\n",
    "negative_samples = train_df[train_df['label'] == 0]\n",
    "\n",
    "# Calculate resampling ratio\n",
    "ratio = len(negative_samples) / len(positive_samples)\n",
    "print(\"ratio\", ratio)\n",
    "\n",
    "# Upsample positive samples\n",
    "upsampled_positive = positive_samples.sample(frac=ratio, replace=True, random_state=42)\n",
    "\n",
    "# Concatenate upsampled positive samples with original negative samples\n",
    "upsampled_df = pd.concat([negative_samples, upsampled_positive])\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "upsampled_df = upsampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check dataset is balanced\n",
    "num_positive = len(upsampled_df[upsampled_df['label'] == 1])\n",
    "num_negative = len(upsampled_df[upsampled_df['label'] == 0])\n",
    "assert num_positive == num_negative, \"Training data is not balanced\"\n",
    "print(\"Training data is balanced\")\n",
    "print(\"Training data length\",len(upsampled_df))\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train = upsampled_df[\"text\"]\n",
    "y_train = upsampled_df['label']\n",
    "X_test = dev_df[\"text\"]\n",
    "y_test = dev_df[\"label\"]\n",
    "\n",
    "# Step 3: Extract features using BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test) # only transform, dont fit\n",
    "\n",
    "# Step 4: Train the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "# Step 5: Evaluate the classifier\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Append predictions to validation dataset\n",
    "tedf1[\"prediction\"] = y_pred\n",
    "print(tedf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample train-train vs train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is balanced\n",
      "Training data length 15162\n",
      "Accuracy: 0.5962732919254659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.57      0.72      1907\n",
      "           1       0.16      0.86      0.27       186\n",
      "\n",
      "    accuracy                           0.60      2093\n",
      "   macro avg       0.57      0.72      0.50      2093\n",
      "weighted avg       0.90      0.60      0.68      2093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows for the 20% testing split\n",
    "test_size = int(len(data) * 0.2)\n",
    "\n",
    "# Step 1: Shuffle and split raw data\n",
    "shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "test_df = shuffled_data.iloc[:test_size]  # First 20%\n",
    "train_df = shuffled_data.iloc[test_size:]  # Last 80%\n",
    "\n",
    "# Separate positive and negative samples in TRAIN data only (don't touch TEST data)\n",
    "positive_samples = train_df[train_df['label'] == 1]\n",
    "negative_samples = train_df[train_df['label'] == 0]\n",
    "\n",
    "# Determine the number of positive samples\n",
    "num_positive_samples = len(positive_samples)\n",
    "\n",
    "# Downsample negative samples to match the number of positive samples\n",
    "downsampled_negative_samples = negative_samples.iloc[0:num_positive_samples]  # Adjust random_state if needed\n",
    "\n",
    "# Combine positive and downsampled negative samples\n",
    "balanced_train_df = pd.concat([positive_samples, downsampled_negative_samples])\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "balanced_train_df = balanced_train_df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle for randomness, adjust random_state if needed\n",
    "\n",
    "# Check dataset is balanced\n",
    "num_positive = len(balanced_train_df[balanced_train_df['label'] == 1])\n",
    "num_negative = len(balanced_train_df[balanced_train_df['label'] == 0])\n",
    "assert num_positive == num_negative, \"Training data is not balanced\"\n",
    "print(\"Training data is balanced\")\n",
    "print(\"Training data length\",len(upsampled_df))\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train = balanced_train_df[\"text\"]\n",
    "y_train = balanced_train_df['label']\n",
    "X_val = test_df[\"text\"]\n",
    "y_val = test_df[\"label\"]\n",
    "\n",
    "# Step 3: Extract features using BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_val_counts = vectorizer.transform(X_val) # only transform, dont fit\n",
    "\n",
    "# Step 4: Train the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "# Step 5: Evaluate the classifier\n",
    "y_pred = clf.predict(X_val_counts)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample train vs dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is balanced\n",
      "Training data length 15162\n",
      "Accuracy: 0.5830945558739254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.55      0.70      1895\n",
      "           1       0.17      0.90      0.29       199\n",
      "\n",
      "    accuracy                           0.58      2094\n",
      "   macro avg       0.58      0.72      0.50      2094\n",
      "weighted avg       0.90      0.58      0.67      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = trdf1.copy()\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "dev_df = tedf1\n",
    "\n",
    "# Separate positive and negative samples in TRAIN data only (don't touch TEST data)\n",
    "positive_samples = train_df[train_df['label'] == 1]\n",
    "negative_samples = train_df[train_df['label'] == 0]\n",
    "\n",
    "# Determine the number of positive samples\n",
    "num_positive_samples = len(positive_samples)\n",
    "\n",
    "# Downsample negative samples to match the number of positive samples\n",
    "downsampled_negative_samples = negative_samples.iloc[0:num_positive_samples]  # Adjust random_state if needed\n",
    "\n",
    "# Combine positive and downsampled negative samples\n",
    "balanced_train_df = pd.concat([positive_samples, downsampled_negative_samples])\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "balanced_train_df = balanced_train_df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle for randomness, adjust random_state if needed\n",
    "\n",
    "# Check dataset is balanced\n",
    "num_positive = len(balanced_train_df[balanced_train_df['label'] == 1])\n",
    "num_negative = len(balanced_train_df[balanced_train_df['label'] == 0])\n",
    "assert num_positive == num_negative, \"Training data is not balanced\"\n",
    "print(\"Training data is balanced\")\n",
    "print(\"Training data length\",len(upsampled_df))\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train = balanced_train_df[\"text\"]\n",
    "y_train = balanced_train_df['label']\n",
    "X_test = dev_df[\"text\"]\n",
    "y_test = dev_df[\"label\"]\n",
    "\n",
    "# Step 3: Extract features using BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test) # only transform, dont fit\n",
    "\n",
    "# Step 4: Train the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "# Step 5: Evaluate the classifier\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
